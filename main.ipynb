{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f6fe8cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded model: google from outputs/stock_price_rnn_google_model.keras\n",
      "Loaded model: meta from outputs/stock_price_rnn_meta_model.keras\n",
      "Loaded model: apple from outputs/stock_price_lstm_apple_model.keras\n",
      "Loaded model: nvidia from outputs/stock_price_lstm_nvidia_model.keras\n",
      "Loaded preprocessor: google from outputs/google_scale.pkl\n",
      "Loaded preprocessor: meta from outputs/meta_scale.pkl\n",
      "Loaded preprocessor: apple from outputs/apple_scale.pkl\n",
      "Loaded preprocessor: nvidia from outputs/nvidia_scale.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\parth\\mp_env\\Lib\\site-packages\\sklearn\\base.py:442: InconsistentVersionWarning: Trying to unpickle estimator MinMaxScaler from version 1.6.0 when using version 1.7.2. This might lead to breaking code or invalid results. Use at your own risk. For more info please refer to:\n",
      "https://scikit-learn.org/stable/model_persistence.html#security-maintainability-limitations\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field, ValidationError\n",
    "import numpy as np\n",
    "import pickle\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "from fastapi import FastAPI, HTTPException\n",
    "import os\n",
    "\n",
    "# Custom metric registration\n",
    "@tf.keras.utils.register_keras_serializable(package=\"Custom\", name=\"symmetric_mean_absolute_percentage_error\")\n",
    "def symmetric_mean_absolute_percentage_error(y_true, y_pred):\n",
    "    numerator = tf.abs(y_true - y_pred)\n",
    "    denominator = (tf.abs(y_true) + tf.abs(y_pred)) / 2\n",
    "    smape = tf.reduce_mean(numerator / denominator) * 100\n",
    "    return smape\n",
    "\n",
    "# FastAPI initialization\n",
    "app = FastAPI()\n",
    "\n",
    "# Define input data model with validation\n",
    "class StockData(BaseModel):\n",
    "    google: List[float] = Field(..., description=\"Google stock time series with 60 values\")\n",
    "    meta: List[float] = Field(..., description=\"Meta stock time series with 60 values\")\n",
    "    apple: List[float] = Field(..., description=\"Apple stock time series with 60 values\")\n",
    "    nvidia: List[float] = Field(..., description=\"NVIDIA stock time series with 60 values\")\n",
    "\n",
    "    @staticmethod\n",
    "    def validate_time_series_length(series, name):\n",
    "        if len(series) != 60:\n",
    "            raise ValueError(f\"{name} time series must have exactly 60 elements.\")\n",
    "        return series\n",
    "\n",
    "    @classmethod\n",
    "    def validate(cls, data):\n",
    "        for company in [\"google\", \"meta\", \"apple\", \"nvidia\"]:\n",
    "            cls.validate_time_series_length(data[company], company)\n",
    "        return data\n",
    "\n",
    "# Model and preprocessor loader\n",
    "class ModelLoader:\n",
    "    def __init__(self, model_paths, preprocessor_paths):\n",
    "        self.model_paths = model_paths\n",
    "        self.preprocessor_paths = preprocessor_paths\n",
    "        self.models = {}\n",
    "        self.preprocessors = {}\n",
    "\n",
    "    def load_models(self):\n",
    "        for name, path in self.model_paths.items():\n",
    "            if os.path.exists(path):\n",
    "                self.models[name] = load_model(path)\n",
    "                print(f\"Loaded model: {name} from {path}\")\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Model file not found: {path}\")\n",
    "\n",
    "    def load_preprocessors(self):\n",
    "        for name, path in self.preprocessor_paths.items():\n",
    "            if os.path.exists(path):\n",
    "                with open(path, 'rb') as f:\n",
    "                    self.preprocessors[name] = pickle.load(f)\n",
    "                print(f\"Loaded preprocessor: {name} from {path}\")\n",
    "            else:\n",
    "                raise FileNotFoundError(f\"Preprocessor file not found: {path}\")\n",
    "\n",
    "    def get_model(self, name):\n",
    "        return self.models.get(name)\n",
    "\n",
    "    def get_preprocessor(self, name):\n",
    "        return self.preprocessors.get(name)\n",
    "\n",
    "# Paths for models and preprocessors\n",
    "model_paths = {\n",
    "    \"google\": \"outputs/stock_price_rnn_google_model.keras\",\n",
    "    \"meta\": \"outputs/stock_price_rnn_meta_model.keras\",\n",
    "    \"apple\": \"outputs/stock_price_lstm_apple_model.keras\",\n",
    "    \"nvidia\": \"outputs/stock_price_lstm_nvidia_model.keras\"\n",
    "}\n",
    "\n",
    "preprocessor_paths = {\n",
    "    \"google\": \"outputs/google_scale.pkl\",\n",
    "    \"meta\": \"outputs/meta_scale.pkl\",\n",
    "    \"apple\": \"outputs/apple_scale.pkl\",\n",
    "    \"nvidia\": \"outputs/nvidia_scale.pkl\"\n",
    "}\n",
    "\n",
    "# Instantiate loader and load resources\n",
    "model_loader = ModelLoader(model_paths, preprocessor_paths)\n",
    "model_loader.load_models()\n",
    "model_loader.load_preprocessors()\n",
    "\n",
    "# Prediction endpoint\n",
    "@app.post(\"/predict\")\n",
    "def predict(data: StockData):\n",
    "    try:\n",
    "        StockData.validate(data.dict())  # Validate time series lengths\n",
    "        results = {}\n",
    "        for company in [\"google\", \"meta\", \"apple\", \"nvidia\"]:\n",
    "            input_series = np.array(getattr(data, company)).reshape(-1, 1)\n",
    "            preprocessor = model_loader.get_preprocessor(company)\n",
    "            model = model_loader.get_model(company)\n",
    "\n",
    "            if not preprocessor or not model:\n",
    "                raise ValueError(f\"Model or preprocessor for {company} not found.\")\n",
    "\n",
    "            scaled_series = preprocessor.transform(input_series).reshape(1, -1, 1)\n",
    "            prediction = model.predict(scaled_series)\n",
    "            predicted_price = preprocessor.inverse_transform(prediction)[0][0]\n",
    "            results[f\"predicted_close_price_{company}\"] = float(predicted_price)\n",
    "\n",
    "        return results\n",
    "    except ValidationError as ve:\n",
    "        raise HTTPException(status_code=422, detail=ve.errors())\n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=422, detail=str(e))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788df0f9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (mp_env)",
   "language": "python",
   "name": "mp_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
